{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.DataLoading import  Datareading\n",
    "from model.OCN import OCN\n",
    "from model.Metric_Loss import Metric_Loss,Nearest_Neighbor\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class = [\"unlabeled\",\"person\",\"bicycle\",\"car\",\"motorcycle\",\"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\"fire hydrant\",\n",
    "\"street sign\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\",\"sheep\",\"cow\",\"elephant\",\"bear\",\"zebra\",\n",
    "\"giraffe\",\"hat\",\"backpack\",\"umbrella\",\"shoe\",\"eye glasses\",\"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\n",
    "\"kite\",\"baseball bat\",\"baseball glove\",\"skateboard\",\"surfboard\",\"tennis racket\",\"bottle\",\"plate\",\"wine glass\",\"cup\",\"fork\",\"knife\",\n",
    "\"spoon\",\"bowl\",\"banana\",\"apple\",\"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hot dog\",\"pizza\",\"donut\",\"cake\",\"chair\",\"couch\",\"potted plant\",\n",
    "\"bed\",\"mirror\",\"dining table\",\"window\",\"desk\",\"toilet\",\"door\",\"tv\",\"laptop\",\"mouse\",\"remote\",\"keyboard\",\"cell phone\",\"microwave\",\"oven\",\n",
    "\"toaster\",\"sink\",\"refrigerator\",\"blender\",\"book\",\"clock\",\"vase\",\"scissors\",\"teddy bear\",\"hair drier\",\"toothbrush\",\"hair brush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading train&test data address: 100%|#################################################| 17/17 [00:00<00:00, 71.20it/s]\n"
     ]
    }
   ],
   "source": [
    "datareading = Datareading(\"./datasets\")\n",
    "transform = transforms.Compose([transforms.ToPILImage(), \n",
    "                                transforms.Resize((360,640)),\n",
    "                                transforms.ToTensor()])\n",
    "trainset, valset = datareading.data_address_reading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epoch, learning_rate = 2.5e-4, model_dir=\"./saved_models\", tensorboard_dir=\"./tensorboard\"):\n",
    "    \n",
    "    # create result and model folders\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)  \n",
    "    if not os.path.exists(tensorboard_dir):\n",
    "        os.mkdir(tensorboard_dir)\n",
    "    # create tensrboard to record loss data\n",
    "    tensorboard_Loss = Evaluation(tensorboard_dir,name = \"Loss\",stats=[\"val_Loss\"])\n",
    "    tensorboard_Training_Metric_Loss = Evaluation(tensorboard_dir,name = \"Training_Metric_Loss\",stats=[\"Train_Metric_Loss\"])\n",
    "    tensorboard_Training_CE_Loss = Evaluation(tensorboard_dir,name = \"Training_CE_Loss\",stats=[\"Train_CE_Loss\"])\n",
    "    tensorboard_Training_Loss = Evaluation(tensorboard_dir,name = \"Training_Loss\",stats=[\"Train_Loss\"])\n",
    "    \n",
    "    tensorboard_Val_Folder_Loss = Evaluation(tensorboard_dir,name = \"Val_Folder_Loss\",stats=[\"Val_Folder_Loss\"])\n",
    "    \n",
    "    \n",
    "    training_folder = trainset.keys()\n",
    "    num_frame = [5,10,20,40,80,160]\n",
    "    # iterate each folder to train certain epoches\n",
    "    for batch in zip(training_folder,num_frame):\n",
    "        folder,num = batch\n",
    "        # reading training data\n",
    "        train_data = datareading.data_reading(trainset[folder],transform)\n",
    "        length = len(train_data)\n",
    "\n",
    "        network = OCN(freeze_FasterRCNN = True,criterion=0.9).cuda()\n",
    "        optimizer = optim.SGD( filter(lambda p: p.requires_grad, network.parameters()), lr=learning_rate ,momentum=0.9, weight_decay=1e-4 )\n",
    "        Metric_Loss = Metric_Loss()\n",
    "        NNB = Nearest_Neighbor()\n",
    "        CE_loss = nn.CrossEntropyLoss()\n",
    "        LOSS = 0\n",
    "        for epoch in tqdm(range(num_epoch),ascii=True, desc=\"epoch at {} ->>\".format(folder)):\n",
    "            me_loss = 0\n",
    "            train_count = 0\n",
    "            for anchor in range(length-1):\n",
    "                anchor_image = train_data[anchor].cuda()\n",
    "                optimizer.zero_grad()\n",
    "                anchor_objects, anchor_features ,_ ,anchor_labels = network(anchor_image)\n",
    "                ce_loss = CE_loss(anchor_objects, anchor_labels)\n",
    "                tensorboard_Training_CE_Loss.write_episode_data(epoch,{\"Train_CE_Loss\":ce_loss.cpu().detach()})\n",
    "                for item in range(anchor+1,length):\n",
    "                    Distance = []\n",
    "                    image_B = train_data[item+1].cuda()\n",
    "                    objects, features_B ,_ ,_ = network(image_B)\n",
    "                    M_loss = Metric_Loss.metric_loss(anchor_features,features_B)\n",
    "                    me_loss += (M_loss + ce_loss)\n",
    "                    me_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_count += 1\n",
    "            me_loss = me_loss/train_count\n",
    "            tensorboard_Training_Metric_Loss.write_episode_data(epoch,{\"Train_Metric_Loss\":me_loss})\n",
    "            train_loss = ce_loss + me_loss\n",
    "            tensorboard_Training_Loss.write_episode_data(epoch,{\"Train_Loss\":train_loss})\n",
    "            \n",
    "            val_data = datareading.data_reading(valset['Frame_video-(160, 200).mp4'],transform)\n",
    "            length = len(val_data)\n",
    "            val_loss = 0\n",
    "            val_count = 0\n",
    "            for anchor in range(length-1):\n",
    "                anchor_image = val_data[anchor].cuda()\n",
    "                objects, features ,_ ,labels = network(anchor_image)\n",
    "                ce_loss = CE_loss(objects, labels)\n",
    "                loss = NNB.mse_loss(features)\n",
    "                val_loss += loss.cpu().detach()\n",
    "                val_count += 1\n",
    "            val_loss = val_loss/val_count\n",
    "            tensorboard_Val_Folder_Loss.write_episode_data(epoch,{\"Val_Folder_Loss\":val_loss})\n",
    "            torch.save(network.state_dict() ,os.path.join(model_dir, \"the_folder_{}_saved_model_at_epoch_{}_loss_{}.pth\".format(folder,epoch,val_loss)))\n",
    "        LOSS+=val_loss\n",
    "        tensorboard_Loss.write_episode_data(num,{\"Val_Loss\":LOSS/num_epoch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(num_epoch = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
